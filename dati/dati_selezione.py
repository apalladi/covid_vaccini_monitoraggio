# -*- coding: utf-8 -*-
"""dati_selezione.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PZFyKTVSr39kJENT-IWRMIWq7MZR4Q7_

## "Table 3" extraction from ISS weekly covid-19 reports
https://www.epicentro.iss.it/coronavirus/sars-cov-2-sorveglianza-dati

See example pdf: 
https://www.epicentro.iss.it/coronavirus/bollettino/Bollettino-sorveglianza-integrata-COVID-19_8-settembre-2021.pdf

Requirements: Java 8+, Python 3.6+
"""

# To use notebook on Google Colab
# %%capture
# !pip install tabula-py

from tabula import read_pdf
import pandas as pd
import numpy as np
from datetime import date
from datetime import timedelta

"""Select mode:
- Automatic (auto = True): table 3 of last available PDF is automatically read
- Manual: you have to specify the PDF link, table number, rep_date
"""

def get_pdf_url(weeks_ago):
  # Define variables
  link_base = 'https://www.epicentro.iss.it/coronavirus/bollettino/Bollettino-sorveglianza-integrata-COVID-19_'
  month_num_to_string = {'1': 'Gennaio', '2': 'Febbraio', '3': 'Marzo', '4': 'Aprile', '5': 'Maggio', '6': 'Giugno', '7': 'Luglio', '8': 'Agosto', '9': 'Settembre', '10': 'Ottobre', '11': 'Novembre', '12': 'Dicembre'}
  # Get url
  today = date.today()
  offset = (today.weekday() - 2) % 7 + 7*weeks_ago  
  last_wednesday = today - timedelta(days=offset)
  link_day = last_wednesday.day
  link_month = month_num_to_string[str(last_wednesday.month)]
  link_year = last_wednesday.year
  url = link_base+f'{link_day}-{link_month}-{link_year}.pdf'
  rep_date = pd.to_datetime(f'{link_day}/{last_wednesday.month}/{link_year}')
  return url, rep_date

# Define mode
auto = True

if auto:
  link_base = 'https://www.epicentro.iss.it/coronavirus/bollettino/Bollettino-sorveglianza-integrata-COVID-19_'
  # Get url of last wednesday PDF
  url, rep_date = get_pdf_url(0)
  # Compose URL of last pdf
  table_index = 2
  try:
    # Read table from url
    raw_tb = read_pdf(url, pages='all', stream=True, silent=True)
  except: # PDF of last wednesday has not been published yet
    # Get PDf of 2 weeks ago
    url, rep_date = get_pdf_url(1)
else:
  # Replace with pdf url
  url = 'https://www.epicentro.iss.it/coronavirus/bollettino/Bollettino-sorveglianza-integrata-COVID-19_22-settembre-2021.pdf'
  # Replace with report data
  rep_date = pd.to_datetime('22/09/2021')
  # Replace with index of table of interest
  table_index = 2
  # Read all tables
  raw_tb = read_pdf(url, pages='all', stream=True, silent=True)

# keep the last and the third last column
columns_to_keep = raw_tb[table_index].columns[[-3,-1]]
to_exclude = '\((.*)|[^a-z-0-9]|\d+-\d+|\d+\+'

df = raw_tb[table_index][columns_to_keep].replace(to_exclude, '', regex=True).replace('', np.nan)
df = df.dropna(subset=columns_to_keep, how='all').fillna(0).astype(np.int64)
df.columns = ['Non vaccinati', 'Immunizzati']
df

# get data
# sum value by age/event

step_ = 4 # groups (=5) are 4 rows (=20) distant (see foo.pdf)

results = [df[col][i:i+step_].sum() for i in np.arange(0, len(df)-step_+1, step_) for col in df.columns]
results

# Create results_df to merge results (#DEBUGONLY)
# no_vax = pd.Series(results[::2])
# yes_vax = pd.Series(results[1::2])
# results_df = pd.concat([no_vax, yes_vax], axis=1)
# results_df.columns = ['Non vaccinati', 'Immunizzati']
# results_df.index = ['Popolazione', 'Diagnosi Sars-CoV-2', 'Ospedalizzazioni', 'Ricoveri in Terapia Intensiva', 'Decessi']
# results_df

# read the original general data csv from apalladi's repo
# https://github.com/apalladi/covid_vaccini_monitoraggio/tree/main/dati

date_parser = lambda x: pd.to_datetime(x, format='%Y/%m/%d')
url = 'https://raw.githubusercontent.com/apalladi/covid_vaccini_monitoraggio/main/dati/dati_ISS_complessivi.csv'
df_0 = pd.read_csv(url, sep=';', parse_dates=['data'], date_parser=date_parser, index_col='data')
df_0

# add the new row at the top of the df
df_0.loc[rep_date] = results
df_0.sort_index(ascending=False, inplace=True)
df_0

# save to a csv
df_0.to_csv('dati_ISS_complessivi.csv', sep=';')

# get data by age
ages = ['12-39', '40-59', '60-79', '80+']
results_ = {age: df[ages.index(age)::step_].stack().values for age in ages}
results_

# load dict as df
df_1 = pd.DataFrame(results_).T
df_1.columns = df_0.columns
df_1.index.rename('età', inplace=True)
df_1.head()

# save to csv
df_1.to_csv(f'data_iss_età_{rep_date.date()}.csv', sep=';')

